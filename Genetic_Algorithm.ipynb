{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Genetic Algorithm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROfalVrCRvXJ"
      },
      "source": [
        "\"\"\"\n",
        "Utility used by the Network class to actually train.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "from keras.datasets import mnist, cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Helper: Early stopping.\n",
        "early_stopper = EarlyStopping(patience=5)\n",
        "\n",
        "\n",
        "def get_gen():\n",
        "    \"\"\"Retrieve  dataset and process the data.\"\"\"\n",
        "    # Set defaults.\n",
        "    nb_classes = 4\n",
        "    batch_size = 64\n",
        "    input_shape = (4228,)\n",
        "\n",
        "    # Get the data.\n",
        "    #(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    #x_train = x_train.reshape(50000, 3072)\n",
        "    #x_test = x_test.reshape(10000, 3072)\n",
        "    import os  \n",
        "    label=[]\n",
        "#os is library used to list down all the files in directory \n",
        "# used for dealing with directory\n",
        "    for i in os.listdir(loc):\n",
        "      if i.split('_')[0]=='Class1':\n",
        "        label.append(0)\n",
        "      elif i.split('_')[0]=='Class2':\n",
        "        label.append(1)\n",
        "      if i.split('_')[0]=='Class 3':\n",
        "        label.append(2)\n",
        "      if i.split('_')[0]=='Hemu':\n",
        "        label.append(3)\n",
        "#we are separating labels \n",
        "\n",
        "\n",
        "    features=[]\n",
        "    for i in os.listdir(loc):\n",
        "      f=cv2.imread(os.path.join(loc,i))\n",
        "      resized_f=cv2.resize(f,(70,70))   #resizing all imgaes\n",
        "      features.append(resized_f)\n",
        "\n",
        "    import numpy as np\n",
        "    X=np.array(features)  #normalizing the pixel values\n",
        "    Y=np.array(label)\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    xtrain,xtest,ytrain,ytest=train_test_split(X,Y)\n",
        "    \n",
        "#\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = to_categorical(y_train, nb_classes)\n",
        "    y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "    return (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)\n",
        "\n",
        "def get_cifar10():\n",
        "    \"\"\"Retrieve the CIFAR dataset and process the data.\"\"\"\n",
        "    # Set defaults.\n",
        "    nb_classes = 10\n",
        "    batch_size = 64\n",
        "    input_shape = (3072,)\n",
        "\n",
        "    # Get the data.\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "    x_train = x_train.reshape(50000, 3072)\n",
        "    x_test = x_test.reshape(10000, 3072)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = to_categorical(y_train, nb_classes)\n",
        "    y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "    return (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)\n",
        "\n",
        "def get_mnist():\n",
        "    \"\"\"Retrieve the MNIST dataset and process the data.\"\"\"\n",
        "    # Set defaults.\n",
        "    nb_classes = 10\n",
        "    batch_size = 128\n",
        "    input_shape = (784,)\n",
        "\n",
        "    # Get the data.\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train = x_train.reshape(60000, 784)\n",
        "    x_test = x_test.reshape(10000, 784)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = to_categorical(y_train, nb_classes)\n",
        "    y_test = to_categorical(y_test, nb_classes)\n",
        "\n",
        "    return (nb_classes, batch_size, input_shape, x_train, x_test, y_train, y_test)\n",
        "\n",
        "def compile_model(network, nb_classes, input_shape):\n",
        "    \"\"\"Compile a sequential model.\n",
        "\n",
        "    Args:\n",
        "        network (dict): the parameters of the network\n",
        "\n",
        "    Returns:\n",
        "        a compiled network.\n",
        "\n",
        "    \"\"\"\n",
        "    # Get our network parameters.\n",
        "    nb_layers = network['nb_layers']\n",
        "    nb_neurons = network['nb_neurons']\n",
        "    activation = network['activation']\n",
        "    optimizer = network['optimizer']\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add each layer.\n",
        "    for i in range(nb_layers):\n",
        "\n",
        "        # Need input shape for first layer.\n",
        "        if i == 0:\n",
        "            model.add(Dense(nb_neurons, activation=activation, input_shape=input_shape))\n",
        "        else:\n",
        "            model.add(Dense(nb_neurons, activation=activation))\n",
        "\n",
        "        model.add(Dropout(0.2))  # hard-coded dropout\n",
        "\n",
        "    # Output layer.\n",
        "    model.add(Dense(nb_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_and_score(network, dataset):\n",
        "    \"\"\"Train the model, return test loss.\n",
        "\n",
        "    Args:\n",
        "        network (dict): the parameters of the network\n",
        "        dataset (str): Dataset to use for training/evaluating\n",
        "\n",
        "    \"\"\"\n",
        "    if dataset == 'cifar10':\n",
        "        nb_classes, batch_size, input_shape, x_train, \\\n",
        "            x_test, y_train, y_test = get_cifar10()\n",
        "    elif dataset == 'mnist':\n",
        "        nb_classes, batch_size, input_shape, x_train, \\\n",
        "            x_test, y_train, y_test = get_mnist()\n",
        "    \n",
        "\n",
        "    model = compile_model(network, nb_classes, input_shape)\n",
        "\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=30,  # using early stopping, so no real limit\n",
        "              verbose=0,\n",
        "              validation_data=(x_test, y_test),\n",
        "              callbacks=[early_stopper])\n",
        "\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    return score[1]  # 1 is accuracy. 0 is loss.\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ImfQHnbRvXK"
      },
      "source": [
        "#network.ipynb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORi0nfCPRvXL"
      },
      "source": [
        "\"\"\"Class that represents the network to be evolved.\"\"\"\n",
        "import random\n",
        "import logging\n",
        "\n",
        "\n",
        "class Network():\n",
        "    \"\"\"Represent a network and let us operate on it.\n",
        "\n",
        "    Currently only works for an MLP.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, nn_param_choices=None):\n",
        "        \"\"\"Initialize our network.\n",
        "\n",
        "        Args:\n",
        "            nn_param_choices (dict): Parameters for the network, includes:\n",
        "                nb_neurons (list): [64, 128, 256]\n",
        "                nb_layers (list): [1, 2, 3, 4]\n",
        "                activation (list): ['relu', 'elu']\n",
        "                optimizer (list): ['rmsprop', 'adam']\n",
        "        \"\"\"\n",
        "        self.accuracy = 0.\n",
        "        self.nn_param_choices = nn_param_choices\n",
        "        self.network = {}  # (dic): represents MLP network parameters\n",
        "\n",
        "    def create_random(self):\n",
        "        \"\"\"Create a random network.\"\"\"\n",
        "        for key in self.nn_param_choices:\n",
        "            self.network[key] = random.choice(self.nn_param_choices[key])\n",
        "\n",
        "    def create_set(self, network):\n",
        "        \"\"\"Set network properties.\n",
        "\n",
        "        Args:\n",
        "            network (dict): The network parameters\n",
        "\n",
        "        \"\"\"\n",
        "        self.network = network\n",
        "\n",
        "    def train(self, dataset):\n",
        "        \"\"\"Train the network and record the accuracy.\n",
        "\n",
        "        Args:\n",
        "            dataset (str): Name of dataset to use.\n",
        "\n",
        "        \"\"\"\n",
        "        if self.accuracy == 0.:\n",
        "            self.accuracy = train_and_score(self.network, dataset)\n",
        "\n",
        "    def print_network(self):\n",
        "        \"\"\"Print out a network.\"\"\"\n",
        "        logging.info(self.network)\n",
        "        logging.info(\"Network accuracy: %.2f%%\" % (self.accuracy * 100))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XO72bxfSG27"
      },
      "source": [
        "#optimizer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FySOio5RSHCM"
      },
      "source": [
        "\"\"\"\n",
        "Class that holds a genetic algorithm for evolving a network.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "from functools import reduce\n",
        "from operator import add\n",
        "import random\n",
        "\n",
        "\n",
        "class Optimizer():\n",
        "    \"\"\"Class that implements genetic algorithm for MLP optimization.\"\"\"\n",
        "\n",
        "    def __init__(self, nn_param_choices, retain=0.4,\n",
        "                 random_select=0.1, mutate_chance=0.2):\n",
        "        \"\"\"Create an optimizer.\n",
        "\n",
        "        Args:\n",
        "            nn_param_choices (dict): Possible network paremters\n",
        "            retain (float): Percentage of population to retain after\n",
        "                each generation\n",
        "            random_select (float): Probability of a rejected network\n",
        "                remaining in the population\n",
        "            mutate_chance (float): Probability a network will be\n",
        "                randomly mutated\n",
        "\n",
        "        \"\"\"\n",
        "        self.mutate_chance = mutate_chance\n",
        "        self.random_select = random_select\n",
        "        self.retain = retain\n",
        "        self.nn_param_choices = nn_param_choices\n",
        "\n",
        "    def create_population(self, count):\n",
        "        \"\"\"Create a population of random networks.\n",
        "\n",
        "        Args:\n",
        "            count (int): Number of networks to generate, aka the\n",
        "                size of the population\n",
        "\n",
        "        Returns:\n",
        "            (list): Population of network objects\n",
        "\n",
        "        \"\"\"\n",
        "        pop = []\n",
        "        for _ in range(0, count):\n",
        "            # Create a random network.\n",
        "            network = Network(self.nn_param_choices)\n",
        "            network.create_random()\n",
        "\n",
        "            # Add the network to our population.\n",
        "            pop.append(network)\n",
        "\n",
        "        return pop\n",
        "\n",
        "    @staticmethod\n",
        "    def fitness(network):\n",
        "        \"\"\"Return the accuracy, which is our fitness function.\"\"\"\n",
        "        return network.accuracy\n",
        "\n",
        "    def grade(self, pop):\n",
        "        \"\"\"Find average fitness for a population.\n",
        "\n",
        "        Args:\n",
        "            pop (list): The population of networks\n",
        "\n",
        "        Returns:\n",
        "            (float): The average accuracy of the population\n",
        "\n",
        "        \"\"\"\n",
        "        summed = reduce(add, (self.fitness(network) for network in pop))\n",
        "        return summed / float((len(pop)))\n",
        "\n",
        "    def breed(self, mother, father):\n",
        "        \"\"\"Make two children as parts of their parents.\n",
        "\n",
        "        Args:\n",
        "            mother (dict): Network parameters\n",
        "            father (dict): Network parameters\n",
        "\n",
        "        Returns:\n",
        "            (list): Two network objects\n",
        "\n",
        "        \"\"\"\n",
        "        children = []\n",
        "        for _ in range(2):\n",
        "\n",
        "            child = {}\n",
        "\n",
        "            # Loop through the parameters and pick params for the kid.\n",
        "            for param in self.nn_param_choices:\n",
        "                child[param] = random.choice(\n",
        "                    [mother.network[param], father.network[param]]\n",
        "                )\n",
        "\n",
        "            # Now create a network object.\n",
        "            network = Network(self.nn_param_choices)\n",
        "            network.create_set(child)\n",
        "\n",
        "            # Randomly mutate some of the children.\n",
        "            if self.mutate_chance > random.random():\n",
        "                network = self.mutate(network)\n",
        "\n",
        "            children.append(network)\n",
        "\n",
        "        return children\n",
        "\n",
        "    def mutate(self, network):\n",
        "        \"\"\"Randomly mutate one part of the network.\n",
        "\n",
        "        Args:\n",
        "            network (dict): The network parameters to mutate\n",
        "\n",
        "        Returns:\n",
        "            (Network): A randomly mutated network object\n",
        "\n",
        "        \"\"\"\n",
        "        # Choose a random key.\n",
        "        mutation = random.choice(list(self.nn_param_choices.keys()))\n",
        "\n",
        "        # Mutate one of the params.\n",
        "        network.network[mutation] = random.choice(self.nn_param_choices[mutation])\n",
        "\n",
        "        return network\n",
        "\n",
        "    def evolve(self, pop):\n",
        "        \"\"\"Evolve a population of networks.\n",
        "\n",
        "        Args:\n",
        "            pop (list): A list of network parameters\n",
        "\n",
        "        Returns:\n",
        "            (list): The evolved population of networks\n",
        "\n",
        "        \"\"\"\n",
        "        # Get scores for each network.\n",
        "        graded = [(self.fitness(network), network) for network in pop]\n",
        "\n",
        "        # Sort on the scores.\n",
        "        graded = [x[1] for x in sorted(graded, key=lambda x: x[0], reverse=True)]\n",
        "\n",
        "        # Get the number we want to keep for the next gen.\n",
        "        retain_length = int(len(graded)*self.retain)\n",
        "\n",
        "        # The parents are every network we want to keep.\n",
        "        parents = graded[:retain_length]\n",
        "\n",
        "        # For those we aren't keeping, randomly keep some anyway.\n",
        "        for individual in graded[retain_length:]:\n",
        "            if self.random_select > random.random():\n",
        "                parents.append(individual)\n",
        "\n",
        "        # Now find out how many spots we have left to fill.\n",
        "        parents_length = len(parents)\n",
        "        desired_length = len(pop) - parents_length\n",
        "        children = []\n",
        "\n",
        "        # Add children, which are bred from two remaining networks.\n",
        "        while len(children) < desired_length:\n",
        "\n",
        "            # Get a random mom and dad.\n",
        "            male = random.randint(0, parents_length-1)\n",
        "            female = random.randint(0, parents_length-1)\n",
        "\n",
        "            # Assuming they aren't the same network...\n",
        "            if male != female:\n",
        "                male = parents[male]\n",
        "                female = parents[female]\n",
        "\n",
        "                # Breed them.\n",
        "                babies = self.breed(male, female)\n",
        "\n",
        "                # Add the children one at a time.\n",
        "                for baby in babies:\n",
        "                    # Don't grow larger than desired length.\n",
        "                    if len(children) < desired_length:\n",
        "                        children.append(baby)\n",
        "\n",
        "        parents.extend(children)\n",
        "\n",
        "        return parents\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iX_mDqjSTvT"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YgecLVFSUUj"
      },
      "source": [
        "\"\"\"Entry point to evolving the neural network. Start here.\"\"\"\n",
        "import logging\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup logging.\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
        "    level=logging.DEBUG,\n",
        "    filename='log.txt'\n",
        ")\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-s1C_p2QSZqq",
        "outputId": "76fdb854-f5d7-40ee-f4e4-559e1c2f412b"
      },
      "source": [
        "def train_networks(networks, dataset):\n",
        "    \"\"\"Train each network.\n",
        "\n",
        "    Args:\n",
        "        networks (list): Current population of networks\n",
        "        dataset (str): Dataset to use for training/evaluating\n",
        "    \"\"\"\n",
        "    pbar = tqdm(total=len(networks))\n",
        "    for network in networks:\n",
        "        network.train(dataset)\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "\n",
        "def get_average_accuracy(networks):\n",
        "    \"\"\"Get the average accuracy for a group of networks.\n",
        "\n",
        "    Args:\n",
        "        networks (list): List of networks\n",
        "\n",
        "    Returns:\n",
        "        float: The average accuracy of a population of networks.\n",
        "\n",
        "    \"\"\"\n",
        "    total_accuracy = 0\n",
        "    for network in networks:\n",
        "        total_accuracy += network.accuracy\n",
        "\n",
        "    return total_accuracy / len(networks)\n",
        "\n",
        "def generate(generations, population, nn_param_choices, dataset):\n",
        "    \"\"\"Generate a network with the genetic algorithm.\n",
        "\n",
        "    Args:\n",
        "        generations (int): Number of times to evole the population\n",
        "        population (int): Number of networks in each generation\n",
        "        nn_param_choices (dict): Parameter choices for networks\n",
        "        dataset (str): Dataset to use for training/evaluating\n",
        "\n",
        "    \"\"\"\n",
        "    optimizer = Optimizer(nn_param_choices)\n",
        "    networks = optimizer.create_population(population)\n",
        "\n",
        "    # Evolve the generation.\n",
        "    for i in range(generations):\n",
        "        logging.info(\"***Doing generation %d of %d***\" %\n",
        "                     (i + 1, generations))\n",
        "\n",
        "        # Train and get accuracy for networks.\n",
        "        train_networks(networks, dataset)\n",
        "\n",
        "        # Get the average accuracy for this generation.\n",
        "        average_accuracy = get_average_accuracy(networks)\n",
        "\n",
        "        # Print out the average accuracy each generation.\n",
        "        logging.info(\"Generation average: %.2f%%\" % (average_accuracy * 100))\n",
        "        logging.info('-'*80)\n",
        "\n",
        "        # Evolve, except on the last iteration.\n",
        "        if i != generations - 1:\n",
        "            # Do the evolution.\n",
        "            networks = optimizer.evolve(networks)\n",
        "\n",
        "    # Sort our final population.\n",
        "    networks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n",
        "\n",
        "    # Print out the top 5 networks.\n",
        "    print_networks(networks[:5])\n",
        "\n",
        "def print_networks(networks):\n",
        "    \"\"\"Print a list of networks.\n",
        "\n",
        "    Args:\n",
        "        networks (list): The population of networks\n",
        "\n",
        "    \"\"\"\n",
        "    logging.info('-'*80)\n",
        "    for network in networks:\n",
        "        network.print_network()\n",
        "\n",
        "def main():\n",
        "    \"\"\"Evolve a network.\"\"\"\n",
        "    generations = 3  # Number of times to evole the population.\n",
        "    population = 6 # Number of networks in each generation.\n",
        "    dataset = 'cifar10'\n",
        "\n",
        "    nn_param_choices = {\n",
        "        'nb_neurons': [64, 128, 256, 512, 768, 1024],\n",
        "        'nb_layers': [1, 2, 3, 4],\n",
        "        'activation': ['relu', 'elu', 'tanh', 'sigmoid'],\n",
        "        'optimizer': ['rmsprop', 'adam', 'sgd', 'adagrad',\n",
        "                      'adadelta', 'adamax', 'nadam'],\n",
        "    }\n",
        "\n",
        "    logging.info(\"***Evolving %d generations with population %d***\" %\n",
        "                 (generations, population))\n",
        "\n",
        "    generate(generations, population, nn_param_choices, dataset)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 2/6 [10:14<18:22, 275.63s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yLtza0NSxQA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GY93KUiG54s"
      },
      "source": [
        "#Brute Forcing approach"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx4-nBu6mjvH"
      },
      "source": [
        "\"\"\"Iterate over every combination of hyperparameters.\"\"\"\n",
        "import logging\n",
        "from network import Network\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Setup logging.\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
        "    level=logging.DEBUG,\n",
        "    filename='brute-log.txt'\n",
        ")\n",
        "\n",
        "def train_networks(networks, dataset):\n",
        "    \"\"\"Train each network.\n",
        "\n",
        "    Args:\n",
        "        networks (list): Current population of networks\n",
        "        dataset (str): Dataset to use for training/evaluating\n",
        "    \"\"\"\n",
        "    pbar = tqdm(total=len(networks))\n",
        "    for network in networks:\n",
        "        network.train(dataset)\n",
        "        network.print_network()\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "\n",
        "    # Sort our final population.\n",
        "    networks = sorted(networks, key=lambda x: x.accuracy, reverse=True)\n",
        "\n",
        "    # Print out the top 5 networks.\n",
        "    print_networks(networks[:5])\n",
        "\n",
        "def print_networks(networks):\n",
        "    \"\"\"Print a list of networks.\n",
        "\n",
        "    Args:\n",
        "        networks (list): The population of networks\n",
        "\n",
        "    \"\"\"\n",
        "    logging.info('-'*80)\n",
        "    for network in networks:\n",
        "        network.print_network()\n",
        "\n",
        "def generate_network_list(nn_param_choices):\n",
        "    \"\"\"Generate a list of all possible networks.\n",
        "\n",
        "    Args:\n",
        "        nn_param_choices (dict): The parameter choices\n",
        "\n",
        "    Returns:\n",
        "        networks (list): A list of network objects\n",
        "\n",
        "    \"\"\"\n",
        "    networks = []\n",
        "\n",
        "    # This is silly.\n",
        "    for nbn in nn_param_choices['nb_neurons']:\n",
        "        for nbl in nn_param_choices['nb_layers']:\n",
        "            for a in nn_param_choices['activation']:\n",
        "                for o in nn_param_choices['optimizer']:\n",
        "\n",
        "                    # Set the parameters.\n",
        "                    network = {\n",
        "                        'nb_neurons': nbn,\n",
        "                        'nb_layers': nbl,\n",
        "                        'activation': a,\n",
        "                        'optimizer': o,\n",
        "                    }\n",
        "\n",
        "                    # Instantiate a network object with set parameters.\n",
        "                    network_obj = Network()\n",
        "                    network_obj.create_set(network)\n",
        "\n",
        "                    networks.append(network_obj)\n",
        "\n",
        "    return networks\n",
        "\n",
        "def main():\n",
        "    \"\"\"Brute force test every network.\"\"\"\n",
        "    dataset = 'cifar10'\n",
        "\n",
        "    nn_param_choices = {\n",
        "        'nb_neurons': [64, 128, 256, 512, 768, 1024],\n",
        "        'nb_layers': [1, 2, 3, 4],\n",
        "        'activation': ['relu', 'elu', 'tanh', 'sigmoid'],\n",
        "        'optimizer': ['rmsprop', 'adam', 'sgd', 'adagrad',\n",
        "                      'adadelta', 'adamax', 'nadam'],\n",
        "    }\n",
        "\n",
        "    logging.info(\"***Brute forcing networks***\")\n",
        "\n",
        "    networks = generate_network_list(nn_param_choices)\n",
        "\n",
        "    train_networks(networks, dataset)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlAkv7wBbEr4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGw0LO7ZYG1I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}